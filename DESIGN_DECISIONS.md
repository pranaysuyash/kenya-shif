# Design Decisions & Architecture Rationale

## Overview

This document explains the key architectural decisions made in the Kenya SHIF Healthcare Policy Analyzer, the reasoning behind them, and the trade-offs considered.

---

## Table of Contents

1. [PDF Extraction Strategy](#pdf-extraction-strategy)
2. [Data Processing Pipeline](#data-processing-pipeline)
3. [Deduplication & Data Cleaning](#deduplication--data-cleaning)
4. [AI Integration Approach](#ai-integration-approach)
5. [Service Structuring](#service-structuring)
6. [Storage & Caching](#storage--caching)
7. [UI/UX Architecture](#uiux-architecture)
8. [Deployment Strategy](#deployment-strategy)

---

## PDF Extraction Strategy

### Problem

The SHIF policy document is a 54-page PDF with mixed content: structured tables on pages 1-18 and semi-structured text on pages 19-54. A single extraction method wouldn't work for both.

### Solution: Hybrid Extraction Approach

#### Pages 1-18: Advanced PyPDF2 Processing

```python
# Why we chose this approach:
âœ… Pages 1-18 contain well-formatted tables with consistent structure
âœ… PyPDF2 extracts with layout preservation
âœ… Allows column detection and structured parsing
âœ… Handles merged cells and complex formatting
```

**Key Features:**

- Preserves spacing and indentation
- Detects column boundaries automatically
- Handles wrapped text and multiline entries
- Works offline (no external APIs)

**Trade-offs:**

- âŒ Slower than tabula for very large documents
- âŒ Memory-intensive for complex layouts
- âœ… But: Better accuracy for policy documents with precise formatting

---

#### Pages 19-54: Tabula Extraction

```python
# Why we chose tabula for later pages:
âœ… Pages 19-54 have less consistent table structure
âœ… Tabula excels at "data islands" in text-heavy content
âœ… Faster extraction for semi-structured data
âœ… Better at detecting tables within prose
```

**Key Features:**

- Detects tables automatically in text
- Handles variable column counts
- Fast extraction
- Returns structured DataFrames

**Trade-offs:**

- âŒ Can merge adjacent tables incorrectly
- âŒ Struggles with complex nested structures
- âœ… But: Acceptable for text-heavy policy sections

---

### Why Not Single Method?

| Method      | Pages 1-18 | Pages 19-54 | Reason                                         |
| ----------- | ---------- | ----------- | ---------------------------------------------- |
| PyPDF2 only | â­â­â­â­â­ | â­â­        | Too slow for large text sections               |
| Tabula only | â­â­â­     | â­â­â­â­    | Misses formatting details in structured tables |
| **Hybrid**  | â­â­â­â­â­ | â­â­â­â­    | **Optimal for mixed content**                  |

---

## Data Processing Pipeline

### Step 1: Raw Extraction

```
PDF Document
    â†“
[PyPDF2 (pages 1-18)] + [Tabula (pages 19-54)]
    â†“
Raw Text Chunks
```

### Step 2: Text Normalization

```python
# Remove artifacts:
âœ… Strip extra whitespace
âœ… Normalize unicode characters
âœ… Remove page breaks and headers
âœ… Fix common OCR errors (if any)
âœ… Standardize field separators

Why: Ensures consistent format for downstream processing
```

### Step 3: Chunking & Structuring

```python
# Split into logical units:
âœ… Service blocks (e.g., "Inpatient Services", "Outpatient")
âœ… Criteria within services
âœ… Coverage details
âœ… Exclusions

Why: Makes it easier for AI to understand context
```

### Step 4: Semantic Enrichment

```python
# Add metadata:
âœ… Service category (inpatient, outpatient, etc.)
âœ… Priority level
âœ… Geographic scope
âœ… Cost implications

Why: Enables advanced filtering and analysis
```

---

## Deduplication & Data Cleaning

### Why Deduplication is Critical

The SHIF document has intentional and unintentional duplicates:

```python
# Example duplicates found:
1. "Dialysis services" - mentioned in:
   - General services (page 15)
   - Chronic disease section (page 28)
   - Specialist referrals (page 35)

2. "Antenatal care visits" - mentioned in:
   - Maternal health (page 8)
   - Preventive services (page 22)
   - Primary health center services (page 18)

# Problem without deduplication:
âŒ Inflated service count (920 â†’ 1200+)
âŒ Contradictions seem more prevalent than they are
âŒ Confuses analytics and reports
âŒ Users see same service multiple times
```

### Deduplication Strategy

#### Level 1: Exact Deduplication

```python
# Remove identical entries:
if normalized_text(entry1) == normalized_text(entry2):
    keep = entry1  # First occurrence
    remove = entry2

# Normalization includes:
âœ… Case normalization (DIALYSIS â†’ dialysis)
âœ… Punctuation removal
âœ… Extra space removal
âœ… Unicode normalization

Result: Removes ~15% of entries
```

#### Level 2: Fuzzy Matching

```python
# Find similar entries:
similarity = levenshtein_distance(entry1, entry2)
if similarity > 85%:
    merge_entries(entry1, entry2)

# Examples:
"Dialysis services in accredited centers" (85% â†’ "Dialysis services")
"Antenatal care visit 4" (87% â†’ "Antenatal care visits")

Result: Removes ~8% of remaining entries
```

#### Level 3: Semantic Deduplication

```python
# Use AI to identify logical duplicates:
if semantic_similarity(entry1, entry2) > 90%:
    merge_with_context_merge()

# Examples:
"IV fluid management" vs "Intravenous fluid therapy"
"Lab testing" vs "Laboratory investigations"
"X-ray imaging" vs "Radiological examination"

Result: Removes ~5% of semantic duplicates
```

### Why This Multi-Level Approach?

| Level        | Why                         | Tradeoff                     |
| ------------ | --------------------------- | ---------------------------- |
| Exact        | Fast, zero false positives  | Misses intentional rewording |
| Fuzzy        | Catches typos & variations  | Can create false positives   |
| Semantic     | Catches true duplicates     | Requires AI, slower          |
| **Combined** | **Best recall & precision** | **Slower but more accurate** |

### Deduplication Results

```
Before deduplication: 1,247 entries
After exact: 1,087 entries (-160, 12.8%)
After fuzzy: 987 entries (-100, 9.2%)
After semantic: 920 entries (-67, 6.8%)

Total reduction: 327 entries (26.2%)
```

---

## AI Integration Approach

### Why Use OpenAI Instead of Local Models?

#### Option 1: Local Models (Ollama, LLaMA)

```
Pros: âœ… Privacy, âœ… Offline, âœ… No API costs
Cons: âŒ Hardware requirements, âŒ Limited accuracy, âŒ Slow
Decision: Not suitable for policy analysis requiring nuance
```

#### Option 2: Open-Source APIs (HuggingFace)

```
Pros: âœ… Lower cost, âœ… More transparent
Cons: âŒ Model variety, âŒ Inference speed, âŒ Worse quality
Decision: Policy analysis needs GPT-4 level accuracy
```

#### Option 3: OpenAI (GPT-4.5-mini, GPT-4.1-mini)

```
Pros: âœ… Best accuracy, âœ… Fast inference, âœ… Context window, âœ… Cost-effective
Cons: âŒ API dependency, âŒ Quota limits
Decision: âœ… Best choice for this use case
```

### Why Deterministic Outputs?

```python
# Configuration:
temperature = 0  # No randomness
seed = 42        # Reproducible results
model = "gpt-4.5-mini"  # Consistent behavior

# Why this matters:
âœ… Same input â†’ Same output (reproducibility)
âœ… Enables testing and validation
âœ… Allows caching of AI results
âœ… Makes contradictions real, not random
```

### AI Usage Patterns

#### 1. Structured Rule Extraction

```python
# Prompt strategy:
Input: Raw text chunk
Output: Structured JSON with fields:
  - Service name
  - Coverage details
  - Exclusions
  - Cost implications

Why: Transforms unstructured text â†’ queryable data
Temperature: 0 (deterministic)
```

#### 2. Contradiction Detection

```python
# Prompt strategy:
Input: Pairs of similar rules
Output: Contradiction analysis:
  - Severity (critical/medium/low)
  - Location (page references)
  - Resolution suggestion

Why: AI identifies nuanced policy conflicts
Temperature: 0 (deterministic)
```

#### 3. Gap Analysis

```python
# Prompt strategy:
Input: Services covered + Kenya healthcare needs
Output: Gap analysis:
  - Service coverage gaps
  - Population groups underserved
  - Disease areas not covered

Why: AI contextualizes coverage against real needs
Temperature: 0 (deterministic)
```

#### 4. Kenya Context Integration

```python
# Prompt strategy:
Input: Service rules + Kenya healthcare context
Output: Contextualized insights:
  - Alignment with national priorities
  - County implementation feasibility
  - Cultural/economic considerations

Why: Grounds analysis in local reality
Temperature: 0 (deterministic)
```

### Why Not Run AI on Every Reload?

```python
# Problem without caching:
âŒ Each page load = new API call ($$$)
âŒ User experiences 10-30s delays
âŒ API quota exhausted quickly
âŒ Inconsistent results if seed changes

# Solution:
âœ… Cache AI outputs in JSON files
âœ… Reuse cached results on reload
âœ… Re-run only on explicit request
âœ… Fallback if cache missing

# Implementation:
unified_analysis_output.json
â”œâ”€â”€ structured_rules
â”œâ”€â”€ contradictions
â”œâ”€â”€ gaps
â”œâ”€â”€ extended_ai
â””â”€â”€ even_more_ai
```

---

## Service Structuring

### Why 920 Structured Rules?

```python
# Each rule captures:
1. Service name
2. Coverage scope (who)
3. Conditions (when)
4. Limitations (what's excluded)
5. Cost implications
6. Cross-references

# Example rule structure:
{
  "service_id": "INP_001",
  "name": "Inpatient Hospitalization",
  "coverage": "All members in public facilities",
  "limitations": [
    "Max 30 days per episode",
    "Requires referral for private facility"
  ],
  "exclusions": ["Cosmetic procedures", "VIP wards"],
  "estimated_cost": "Full coverage",
  "references": ["page 12, section 3.1"]
}
```

### Why So Many?

```
Services breakdown (920 total):
â”œâ”€â”€ Inpatient Services: 156
â”œâ”€â”€ Outpatient Services: 234
â”œâ”€â”€ Preventive Services: 142
â”œâ”€â”€ Diagnostic Services: 156
â”œâ”€â”€ Specialty Services: 89
â””â”€â”€ Administrative/Other: 143

Why not consolidate?
âŒ Would lose policy detail
âŒ Contradictions would be hidden in consolidation
âŒ Coverage analysis would be less precise
âŒ Recommendations couldn't be service-specific

âœ… Granularity enables precise gap analysis
âœ… Allows filtering by service type
âœ… Reveals hidden contradictions
âœ… Supports detailed recommendations
```

---

## Storage & Caching

### Why JSON for Everything?

```python
# Options considered:
1. SQL Database
   âŒ Overkill for static analysis
   âŒ Can't deploy to serverless environments
   âŒ Requires schema maintenance

2. CSV Files
   âŒ Doesn't preserve nested structures
   âŒ Hard to update specific entries
   âŒ Merge conflicts in version control

3. JSON Files
   âœ… Portable across platforms
   âœ… Human-readable for debugging
   âœ… Git-friendly (version control)
   âœ… Works on all deployment platforms
   âœ… Streamlit-native support

Decision: âœ… JSON + in-memory processing
```

### File Organization

```
outputs/
â”œâ”€â”€ unified_analysis_output.json       # Main output (1-2 MB)
â”œâ”€â”€ ai_recommendations.json             # AI analysis (cached)
â”œâ”€â”€ ai_gap_analysis.json                # Gap analysis (cached)
â”œâ”€â”€ ai_contradiction_analysis.json      # Contradiction analysis (cached)
â”œâ”€â”€ ai_kenya_insights.json              # Kenya context (cached)
â””â”€â”€ ai_predictive_analysis.json         # Scenario analysis (cached)
```

### Why Separate Files for AI Outputs?

```
Benefit 1: Modularity
âœ… Each AI analysis is independent
âœ… Can regenerate one without affecting others
âœ… Faster to update single analysis

Benefit 2: Performance
âœ… Only load needed files
âœ… Smaller file sizes = faster loading
âœ… Parallel processing possible

Benefit 3: Debugging
âœ… Easy to identify which analysis failed
âœ… Can inspect individual AI outputs
âœ… Better error tracking

Trade-off:
âŒ More files to manage
âœ… But: Benefits outweigh complexity
```

### Caching Strategy

```python
# On app startup:
1. Check if unified_analysis_output.json exists
2. If yes: Load into memory (fast, <100ms)
3. If no: Show "Run Extraction" button

# On extraction request:
1. Run live analysis (5-10 minutes)
2. Save to unified_analysis_output.json
3. Also cache individual AI outputs

# On AI button click:
1. Check if ai_[type].json exists
2. If yes: Load from cache (instant)
3. If no: Call OpenAI API and cache result
4. Display result to user

# Why this works:
âœ… Subsequent loads are instant
âœ… Users don't re-run expensive analysis
âœ… AI results are reproducible
âœ… Offline viewing possible (after first load)
```

---

## UI/UX Architecture

### Why 6 Tabs Instead of Single Page?

```
Dashboard Overview
    â”œâ”€â”€ Quick stats
    â”œâ”€â”€ Summary metrics
    â””â”€â”€ Visual overview

Structured Rules
    â”œâ”€â”€ Filterable service list
    â”œâ”€â”€ Detail view
    â””â”€â”€ Drill-down capability

Contradictions & Gaps
    â”œâ”€â”€ Contradiction explorer
    â”œâ”€â”€ Gap analysis
    â””â”€â”€ Severity filters

Kenya Context
    â”œâ”€â”€ National priority alignment
    â”œâ”€â”€ County considerations
    â””â”€â”€ Implementation readiness

Advanced Analytics
    â”œâ”€â”€ Trends and patterns
    â”œâ”€â”€ Custom filtering
    â””â”€â”€ Export options

AI Insights
    â”œâ”€â”€ Contradiction analysis
    â”œâ”€â”€ Gap analysis
    â”œâ”€â”€ Policy recommendations
    â””â”€â”€ Predictive scenarios
```

### Why This Structure?

| Tab                | Why                    | Benefit                                  |
| ------------------ | ---------------------- | ---------------------------------------- |
| Overview           | Entry point            | Users understand what they're looking at |
| Structured         | Deep dive              | Explore individual services              |
| Contradictions     | Problem identification | Find issues systematically               |
| Kenya Context      | Local relevance        | Connect to real-world implementation     |
| Advanced Analytics | Power users            | Detailed exploration                     |
| AI Insights        | Strategic decisions    | Evidence-based recommendations           |

### AI Insights Tab - 5 Interactive Buttons

The AI Insights tab provides five powerful analysis buttons:

#### 1. ğŸ” Analyze Contradictions

Purpose: Identify policy conflicts that could harm patients or confuse providers

Analysis: Uses medical expertise (Dr. Sarah Mwangi persona) across 10+ specialties

Output: Structured analysis showing:

- Contradiction type and severity
- Medical specialty affected
- Clinical impact (HIGH/MEDIUM/LOW)
- Patient safety risks
- Provider confusion implications
- Recommended fixes with medical evidence

Example: Detects dialysis session frequency conflicts between procedures

#### 2. ğŸ“Š Analyze Coverage Gaps

Purpose: Identify missing or insufficient healthcare coverage areas

Analysis: Matches policy against Kenya health needs and disease burden

Output: Gap analysis with:

- Service coverage gaps
- Population groups underserved
- Disease areas not covered
- Geographic disparities
- County-level implementation challenges
- Priority recommendations

Example: Identifies mental health coverage insufficiency for specific age groups

#### 3. ğŸ“‹ Executive Policy Recommendations

Purpose: Generate strategic policy improvement recommendations

Analysis: Reviews all 920+ services against healthcare standards

Output: Executive-level insights including:

- High-level policy gaps
- Facility-level mismatches
- Resource utilization issues
- Service prioritization recommendations
- Implementation readiness assessment
- Cost-benefit analysis

Example: Recommends consolidating duplicative services, reallocating resources

#### 4. ğŸŒ Kenya-Specific Insights

Purpose: Ground analysis in Kenya's healthcare context and realities

Analysis: Applies Kenya healthcare system knowledge (facility levels 1-6, resources, disease burden)

Output: Contextualized insights:

- Alignment with national health priorities
- County implementation feasibility
- Cultural and economic considerations
- Healthcare system capacity constraints
- Equity and access implications
- Regional variation recommendations

Example: Adapts recommendations for different county healthcare maturity levels

#### 5. ğŸ”® Predictive Scenario Analysis

Purpose: Project policy outcomes under different implementation scenarios

Analysis: Runs AI models against user-provided scenarios

Input: User describes scenario (e.g., "Baseline with moderate readiness, scale over 12 months")

Output: Predictive analysis with:

- Expected implementation timeline
- Resource requirements
- Provider adoption challenges
- Patient impact projections
- Risk factors and mitigation
- Success indicators and KPIs

Example: Projects coverage expansion outcomes under different scaling timelines

### Why Session State for AI Insights?

```text
Problem: Streamlit reruns entire script on every interaction
- Clicking "Analyze Contradictions" button triggers rerun
- Instance variables (self.results) reset on each rerun
- User would see "Load results" even though data existed

Solution: Use st.session_state (persists across reruns)
- Store extracted data in session state on startup
- Sync to instance variables
- Results remain available during entire user session
- All buttons work immediately without re-extraction

Result:
âœ… Click AI Insights tab â†’ sees cached data
âœ… Click any button â†’ works immediately
âœ… Multiple analyses possible â†’ all reference same data
âœ… Fast interactions â†’ no re-extraction needed
```

### Why Documentation in Sidebar?

```text
Initial design: Side panel (abandoned)
âŒ Takes up 1/3 of screen
âŒ Closes on interaction
âŒ Can't reference while working

Current design: Full-screen view
âœ… Full documentation visible
âœ… Doesn't interfere with tabs
âœ… Can reference while working
âœ… Clean, distraction-free reading

Access: Sidebar dropdown â†’ Button â†’ Full screen
```

---

## Deployment Strategy

### Why Multiple Deployment Options?

```python
# Different deployments for different needs:

1. Local Development
   âœ… Full file system access
   âœ… Persistent storage
   âœ… All features work
   â””â”€ Command: streamlit run app.py

2. Replit (Free tier)
   âœ… Easy sharing
   âœ… Built-in environment
   âš ï¸ Data resets after inactivity
   âš ï¸ Users must download results
   â””â”€ Best for: Demos, temporary analysis

3. Vercel (Serverless)
   âœ… Fast deployment
   âš ï¸ No persistent storage
   âš ï¸ Functions timeout after 60s
   âš ï¸ PDF extraction not feasible
   â””â”€ Best for: API backend only

4. Streamlit Cloud (Recommended)
   âœ… Easy deployment from GitHub
   âœ… Free tier available
   âœ… Handles Streamlit-specific features
   âš ï¸ Limited compute on free tier
   â””â”€ Best for: Production use
```

### Why Streamlit Cloud as Primary?

```
Requirements for production:
âœ… Easy updates (git push â†’ live)
âœ… Persistent cache between runs
âœ… Enough compute for PDF processing
âœ… Session state support
âœ… Authentication ready
âœ… Cost-effective

Streamlit Cloud meets all: âœ… Chosen as primary
```

### Why Download-First for Cloud?

```
Problem: Cloud environments have ephemeral storage
Solution: Users download results immediately after generation

Flow:
1. User runs extraction (5-10 min)
2. Download JSON automatically offered
3. User can upload previous JSON on next visit
4. Historical analysis tab loads from uploaded file

Why this design:
âœ… Works on all cloud platforms
âœ… Gives users data ownership
âœ… Enables reproducibility
âœ… Solves storage limitations
```

---

## Performance Optimization Decisions

### Why Lazy Loading?

```python
# Without lazy loading:
âŒ App takes 30s to initialize
âŒ All tabs load on startup
âŒ Large files loaded into memory
âŒ Poor mobile experience

# With lazy loading:
âœ… Quick app startup (2-3s)
âœ… Only active tab processed
âœ… Memory usage minimal
âœ… Better mobile experience

# Implementation:
Each tab has conditional rendering:
if tab_active:
    render_expensive_component()
```

### Why Expanders for Details?

```python
# Without expanders:
âŒ Huge scrolling pages
âŒ Information overload
âŒ Hard to find key details
âŒ Visual clutter

# With expanders:
âœ… Clean, organized layout
âœ… Users expand only what interests them
âœ… Progressive information disclosure
âœ… Faster page loads (collapsed content not rendered)

# Example:
with st.expander("Show contradiction details"):
    st.dataframe(contradictions_df)
```

---

## Error Handling & Resilience

### Why Fallback Models?

```python
# Primary model: gpt-4.5-mini (higher accuracy)
# Fallback model: gpt-4.1-mini (lower cost, acceptable accuracy)

# Scenario: Primary model quota exceeded
1. Try gpt-4.5-mini â†’ Fails with quota error
2. Automatically try gpt-4.1-mini â†’ Succeeds
3. User doesn't experience failure

# Scenario: Both models unavailable
1. Try both â†’ Both fail
2. Show warning: "AI features temporarily unavailable"
3. Core features (extraction, contradictions) still work
4. User can use pattern-based analysis as fallback
```

### Why Cached Results Fallback?

```python
# Problem: Live extraction fails (API error, timeout)
# Solution: Load previous successful results

Flow:
try:
    results = live_extraction()
except Exception:
    st.info("Attempting to load cached results...")
    if cached_file.exists():
        results = load_json(cached_file)
        st.success("âœ… Using previous cached results")
    else:
        st.error("âŒ No cache available. Please run extraction.")

# Benefit: Better user experience, reduced frustration
```

---

## Summary: Design Philosophy

| Principle               | Implementation                       | Benefit                |
| ----------------------- | ------------------------------------ | ---------------------- |
| **Hybrid approach**     | Different methods for different data | Optimal accuracy       |
| **Deterministic**       | temperature=0, seed=42               | Reproducible, testable |
| **Cached results**      | Save AI outputs to JSON              | Fast subsequent loads  |
| **Granular data**       | 920 detailed rules                   | Precise analysis       |
| **Multi-level dedup**   | Exact + fuzzy + semantic             | Accurate counts        |
| **Multiple deployment** | Local, Replit, Streamlit, Vercel     | Flexibility            |
| **Lazy loading**        | Only render active tabs              | Performance            |
| **Fallback systems**    | Cached results, alternative models   | Resilience             |
| **Documentation**       | In-app + GitHub                      | Accessibility          |

---

## Future Enhancements

### Potential Improvements

```python
# 1. Real-time update mechanism
   When SHIF policy updates:
   - Automatically fetch new PDF
   - Re-extract and re-analyze
   - Notify users of changes

# 2. Multi-language support
   - Translate rules to Swahili
   - Support regional languages
   - Localize for counties

# 3. Collaborative features
   - Users can annotate contradictions
   - Vote on gap importance
   - Community context contributions

# 4. Predictive analytics
   - Scenario modeling for policy changes
   - Impact analysis
   - Cost projections

# 5. Integration with external data
   - Healthcare facility data
   - Disease prevalence data
   - County implementation status
```

---

## Conclusion

Every architectural decision in this system was made to balance:

- **Accuracy** vs Speed
- **Features** vs Simplicity
- **Cost** vs Quality
- **Flexibility** vs Reliability

The result is a robust, scalable system that works across devices and deployment platforms while maintaining data accuracy and user experience.
